import argparse
import pickle
import os  # Importação para verificar a existência dos arquivos
from Tiling import tiling
from Pre_processing import pre_processing
from Data_split import data_split
from Training import train
from Independent_test import independent_test
from Hyperparameter_optimisation import hyperparameter_optimisation
from Data_visualisation import data_visualisation
from Grad_Cam import grad_cam


def save_variable(var, filename):
    """Save a variable to a file using pickle serialization.

    This function serializes a given variable and writes it to a specified file in binary format 
    using the pickle module. It returns the filename where the variable has been saved.

    Args:
        var (any): The variable to be saved to a file.
        filename (str): The name of the file where the variable will be stored.

    Returns:
        str: The filename where the variable has been saved.
    """
    with open(filename, 'wb') as pickle_f:
        pickle.dump(var, pickle_f)
    return filename


def load_variable(filename):
    """Load a variable from a file using pickle serialization.

    This function opens a specified file in binary read mode and uses the pickle module to 
    deserialize the contents into a Python variable. It returns the loaded variable for further use.

    Args:
        filename (str): The path to the file from which the variable will be loaded.

    Returns:
        any: The deserialized variable loaded from the specified file.
    """
    with open(filename, 'rb') as pickle_f:
        var = pickle.load(pickle_f)
    return var
import argparse
import os

def run(**kwargs):
    """
    This is the main entry point of the HEAL package.
    Default parameters:
        label_file = "label_file.csv";
        testing_label_file = None;
        models = ['ResNet50'];
        training_mode = "single_round";
        procedure = ["Tiling", "Pre_processing", "Data_Split", "Training",  "Hyperparameter_optimisation", "Testing", "Survival_analysis"].

    **Parameter description**
        1) label_file: (string) the file path of the input csv format file. The csv file
        contains two columns,
            col_1: "Image_path" (the image file paths of each patient)
            col_2: "Label" (the label of the corresponding patient, each sample could
                contains several labels.)
        2) testing_label_file: (string) the file path of the input csv format file for
         model training.
            This parameter is None as default, the testing dataset will be split from
            the "label file".
            If the user input test file, this file will be used for independent test.
        3) models: (list) specify the deep learning models used for model training.
            The available options are: VGG11, VGG19, ResNet36, ResNet50, Inception-V3,
            SENet, ResNeXt ...;
        4) training_mode: (string) specify the training mode, single round training or
        10-fold cross-validation;
        5) procedure: (list) specify the detailed processing steps for the model training.
        The entire processing steps is consisted by 5 steps:
                a) tiling: segment the whole slide image into small patches, the default
                image size is 1000*1000;
                b) data_split: split the dataset into training dataset, validation dataset,
                and testing dataset;
                c) training: to train the model based on the input images and the specified
                models;
                d) testing: to test the model performance based on the optimised model;
                e) survival_analysis: (Optional) to conduct the survival analysis based on
                 the output of the independent test.
    """
    print(kwargs.items())

    # Parse the input parameters
    _label_file = kwargs.get("label_file", None)
    _testing_label_file = kwargs.get("testing_label_file", None)
    _models = kwargs.get("models", None)
    _training_mode = kwargs.get("training_mode", "Single_round")
    _procedure = kwargs.get("procedure", None)
    _tile_info = kwargs.get("tile_info", [256, 0])  # Default values for tile size and level
    _filter_model = kwargs.get("filter_model", None)
    _extra_test_file = kwargs.get("extra_testing_label_file", None)
    _extra_testing_pre_processing_enable = kwargs.get("extra_testing_pre_processing_enable", False)

    _label_file_tiled = "HEAL_Workspace/outputs/label_file_tiled.csv" if _label_file else None
    _test_label_file_tiled = "HEAL_Workspace/outputs/test_label_file_tiled.csv" if _testing_label_file else None

    # Loop for each procedure
    for _proc in procedure:
        if _proc == "Tiling":
            print("[INFO] Start tiling ...")
            tiling.tiling(label_file, testing_label_file, _tile_size=tile_info[0], _tile_level=tile_info[1])
        elif _proc == "Pre_processing":
            print("[INFO] Image pre-processing: color correction and blur detection ...")
            _img_path_template = input("Please input the path of the template image: ")
            pre_processing.pre_processing(_img_path_template=_img_path_template)
        elif _proc == "Data_split":
            print("[INFO] Data split ...")
            data_split.data_split(_label_file_tiled, _test_label_file_tiled, test_ratio=0.5)
        elif _proc == "Hyperparameter_optimisation":
            print("[INFO] Hyperparameter optimization ...")
            hyperparameter_optimisation.tuning()
        elif _proc == "Training":
            print("[INFO] Training ...")
            train.train(models, tile_size=tile_info[0], CV_Enable=(training_mode == "Cross_validation"))
        elif _proc == "Testing":
            print("[INFO] Testing ...")
            independent_test.independent_test(models, tile_info)
        elif _proc == "Data_visualisation":
            print("[INFO] Data visualization ...")
            data_visualisation.data_visualisation(tile_info)
        elif _proc == "Grad_CAM":
            print("[INFO] Grad-CAM visualization ...")
            grad_cam.grad_cam()

    print(label_file, testing_label_file, models, training_mode, procedure)



def main():
    parser = argparse.ArgumentParser(description="Run the HEAL package pipeline for image analysis and model training.")
    
    parser.add_argument('--label_file', type=str, required=True, 
                        help="(required) Path to the label file containing the training data.")
    parser.add_argument('--testing_label_file', type=str, default=None, 
                        help="(optional) Path to the testing label file. If not provided, the main label file will be used for testing.")
    parser.add_argument('--models', type=str, nargs='+', required=True, 
                        help=("(required) List of models to use for training and testing:"
                                "AlexNet, DenseNet161, EFF-NET, GoogleNet, InceptionV3, MNASNET, "
                                "MobileNetV2, ResNet101, ResNet152, ResNet18, ResNet34, ResNet50, "
                                "ShuffleNetV2, Vgg16, Vgg16_BN, Vgg19, Vgg19_BN, WideResNet101, "
                                "WideResNet50"
                            ))
    parser.add_argument('--training_mode', type=str, choices=['Single_round', 'Cross_validation'], default='Single_round',
                        help="(optional) Training mode, either single_round or Cross_validation. Default is single_round.")
    parser.add_argument('--procedure', type=str, nargs='+', required=True, 
                        help=("(required) Procedure steps to run, specified as a list of strings:"
                                "Tiling: Divides the images into smaller tiles for processing."
                                "Pre_processing: Prepares the images for analysis."
                                "Data_split: Splits the data into training, validation, and testing sets."
                                "Hyperparameter_optimisation: Optimises the hyperparameters of the model."
                                "Training: Trains the model using the training data."
                                "Testing: Tests the model using the testing data."
                                "Data_visualisation: Visualises the processed data."
                                "Grad_CAM: Uses Grad-CAM to visualise the key regions of the image."
                            ))
    parser.add_argument('--tile_info', type=int, nargs=2, default=[1000, 0], 
                        help="(optional) Tile size and level, specified as two integers. Default is [1000, 0].")
    parser.add_argument('--filter_model', type=str, default=None, 
                        help="(optional) Model filtering criteria.")
    parser.add_argument('--extra_testing_label_file', type=str, default=None, 
                        help="(optional) Path to an additional testing label file.")
    parser.add_argument('--extra_testing_pre_processing_enable', action='store_true', 
                        help="(optional) Whether to enable pre-processing for the extra testing set.")
    
    args = parser.parse_args()
    
    run(
        label_file=args.label_file,
        testing_label_file=args.testing_label_file,
        models=args.models,
        training_mode=args.training_mode,
        procedure=args.procedure,
        tile_info=args.tile_info,
        filter_model=args.filter_model,
        extra_testing_label_file=args.extra_testing_label_file,
        extra_testing_pre_processing_enable=args.extra_testing_pre_processing_enable
    )

if __name__ == "__main__":
    main()